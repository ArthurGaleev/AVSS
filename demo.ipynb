{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c6d2659e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6d2659e",
        "outputId": "d32b695b-aaf4-4b6c-ff0f-cc8cd97eb550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content\")\n",
        "!rm -rf \"AVSS\"\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "30a27f2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30a27f2a",
        "outputId": "f3116a2b-84a1-412f-f3c9-d5d10402e2d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AVSS'...\n",
            "remote: Enumerating objects: 1697, done.\u001b[K\n",
            "remote: Counting objects: 100% (432/432), done.\u001b[K\n",
            "remote: Compressing objects: 100% (291/291), done.\u001b[K\n",
            "remote: Total 1697 (delta 245), reused 251 (delta 131), pack-reused 1265 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1697/1697), 346.45 KiB | 5.97 MiB/s, done.\n",
            "Resolving deltas: 100% (1129/1129), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ArthurGaleev/AVSS.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c48918b8",
      "metadata": {
        "id": "c48918b8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"AVSS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install requirements"
      ],
      "metadata": {
        "id": "vb9UCa2g7SnY"
      },
      "id": "vb9UCa2g7SnY"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f2c6714b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2c6714b",
        "outputId": "8484af91-d1e2-433c-df27-7f55c64c12d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uv\n",
            "  Downloading uv-0.9.17-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.9.17-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.1/22.1 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.9.17\n",
            "Using CPython \u001b[36m3.13.7\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 5.43s\u001b[0m\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `sru==2.6.0` does not have an extra named `cuda`\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m142 packages\u001b[0m \u001b[2min 1m 32s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m142 packages\u001b[0m \u001b[2min 866ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mantlr4-python3-runtime\u001b[0m\u001b[2m==4.9.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maudioop-lts\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maudioread\u001b[0m\u001b[2m==3.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mblack\u001b[0m\u001b[2m==25.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbleach\u001b[0m\u001b[2m==6.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.11.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcfgv\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcomet-ml\u001b[0m\u001b[2m==3.54.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mconfigobj\u001b[0m\u001b[2m==5.0.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdistlib\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdotenv\u001b[0m\u001b[2m==0.9.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdulwich\u001b[0m\u001b[2m==0.24.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1meverett\u001b[0m\u001b[2m==3.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflatbuffers\u001b[0m\u001b[2m==25.9.23\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.61.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgammatone\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgdown\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.45\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhydra-core\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midentify\u001b[0m\u001b[2m==2.6.15\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1misort\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.25.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjsonschema-specifications\u001b[0m\u001b[2m==2025.9.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjulius\u001b[0m\u001b[2m==0.2.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkaggle\u001b[0m\u001b[2m==1.7.4.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlazy-loader\u001b[0m\u001b[2m==0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlibrosa\u001b[0m\u001b[2m==0.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.15.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.46.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmsgpack\u001b[0m\u001b[2m==1.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mninja\u001b[0m\u001b[2m==1.13.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnodeenv\u001b[0m\u001b[2m==1.9.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.63.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1momegaconf\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.23.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpathspec\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpesq\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpooch\u001b[0m\u001b[2m==1.8.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpre-commit\u001b[0m\u001b[2m==4.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprimepy\u001b[0m\u001b[2m==1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.23\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpysocks\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpystoi\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-box\u001b[0m\u001b[2m==6.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-slugify\u001b[0m\u001b[2m==8.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytokens\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mreferencing\u001b[0m\u001b[2m==0.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests-toolbelt\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrpds-py\u001b[0m\u001b[2m==0.30.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msemantic-version\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msentry-sdk\u001b[0m\u001b[2m==2.47.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msimplejson\u001b[0m\u001b[2m==3.20.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoundfile\u001b[0m\u001b[2m==0.13.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoxr\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msru\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstandard-aifc\u001b[0m\u001b[2m==3.13.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstandard-chunk\u001b[0m\u001b[2m==3.13.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstandard-sunau\u001b[0m\u001b[2m==3.13.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtext-unidecode\u001b[0m\u001b[2m==1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch-audiomentations\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch-pitch-shift\u001b[0m\u001b[2m==1.2.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.8.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mvirtualenv\u001b[0m\u001b[2m==20.35.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwandb\u001b[0m\u001b[2m==0.22.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwebencodings\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==2.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwurlitzer\u001b[0m\u001b[2m==3.1.1\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install uv\n",
        "!uv sync"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download models checkpoints and datasets"
      ],
      "metadata": {
        "id": "Tn7xf9K57bhl"
      },
      "id": "Tn7xf9K57bhl"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f97dcc9a",
      "metadata": {
        "id": "f97dcc9a"
      },
      "outputs": [],
      "source": [
        "# download our dataset and all models.\n",
        "# !uv run scripts/download_gdrive.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "42db6d29",
      "metadata": {
        "id": "42db6d29"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/AVSS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive"
      ],
      "metadata": {
        "id": "h_KYliRK7nTI"
      },
      "id": "h_KYliRK7nTI"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0b71e498",
      "metadata": {
        "id": "0b71e498",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6ae9ab-8af0-4285-9dce-525f05264f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1lzO_cyN0WKof1rtnCPZpN-BHcELO-85c\n",
            "From (redirected): https://drive.google.com/uc?id=1lzO_cyN0WKof1rtnCPZpN-BHcELO-85c&confirm=t&uuid=9110336d-f9ae-4a00-9cf4-b22a29fecc89\n",
            "To: /content/AVSS/data/models/rtfs-4-reuse.pth\n",
            "100%|██████████| 71.2M/71.2M [00:01<00:00, 48.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1IU4mFseGPtac6g58jTS48GzlMI1wMJQ8\n",
            "From (redirected): https://drive.google.com/uc?id=1IU4mFseGPtac6g58jTS48GzlMI1wMJQ8&confirm=t&uuid=f996f50a-783d-4556-ba56-e690cd217a32\n",
            "To: /content/AVSS/data/models/dprnn.pth\n",
            "100%|██████████| 31.7M/31.7M [00:00<00:00, 187MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1wu_S9wpiZmpyAZosvWTCYC9W6zD6nAVe\n",
            "From (redirected): https://drive.google.com/uc?id=1wu_S9wpiZmpyAZosvWTCYC9W6zD6nAVe&confirm=t&uuid=ac3edd28-d923-437b-b201-a061d529149b\n",
            "To: /content/AVSS/data/datasets.zip\n",
            "100%|██████████| 6.24G/6.24G [00:53<00:00, 117MB/s]\n"
          ]
        }
      ],
      "source": [
        "from scripts.download_gdrive import download_dataset, download_models\n",
        "RTFS_MODEL_PATH=\"data/models/rtfs-4-reuse.pth\" #Our SOTA Model\n",
        "DPRNN_MODEL_PATH=\"data/models/dprnn.pth\" #Our best dprnn checkpoint\n",
        "DATASET_PATH=\"data/datasets\"#Where you download dataset from google drive\n",
        "DATASET_LINK=\"https://drive.google.com/uc?id=1wu_S9wpiZmpyAZosvWTCYC9W6zD6nAVe\"\n",
        "#If returns\n",
        "GDRIVE_URLS = {\n",
        "    \"models\": {\n",
        "        # rtfs-4-reuse, links can be found in scripts/download_gdrive\n",
        "        \"https://drive.google.com/uc?id=1lzO_cyN0WKof1rtnCPZpN-BHcELO-85c\": RTFS_MODEL_PATH,\n",
        "        \"https://drive.google.com/uc?id=1IU4mFseGPtac6g58jTS48GzlMI1wMJQ8\":DPRNN_MODEL_PATH\n",
        "    },\n",
        "    \"dataset\": {\n",
        "        DATASET_LINK:DATASET_PATH#Put your dataset link here\n",
        "    }\n",
        "}\n",
        "download_models(GDRIVE_URLS) #if models dont download you can download them manually to data/models\n",
        "download_dataset(GDRIVE_URLS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yandex Disk"
      ],
      "metadata": {
        "id": "F7yDHRvh7kah"
      },
      "id": "F7yDHRvh7kah"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b4ddc315",
      "metadata": {
        "id": "b4ddc315"
      },
      "outputs": [],
      "source": [
        "# you can also specify a link to your yandex disk zip dataset for it to download during training ot infernce, see src/datasets/yandex_download for details\n",
        "# used this to check inference val/test folders\n",
        "os.environ[\"YANDEX_DISK_URL\"]=\"https://disk.360.yandex.ru/d/5pz96ysIZi33IQ\"  # dla_dataset with small train, but whole val/test\n",
        "download_name = \"dla_dataset_small_av\"\n",
        "\n",
        "# used this to check inference on one folder with and w/o gt in corresponding sections\n",
        "# os.environ[\"YANDEX_DISK_URL\"]=\"https://disk.360.yandex.ru/d/ML0ey9j1KJOdtg\"  # dla_dataset with only val in one folder\n",
        "# download_name = \"custom_dataset\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlencode\n",
        "import requests\n",
        "\n",
        "\n",
        "data_dir = Path(\"/content/AVSS/data/datasets\")\n",
        "if not (data_dir / download_name / \"audio\").exists():\n",
        "    try:\n",
        "        data_dir.mkdir(exist_ok=True, parents=True)\n",
        "        download_info = {\n",
        "            \"base_url\": \"https://cloud-api.yandex.net/v1/disk/public/resources/download?\",\n",
        "            \"public_key\": os.getenv(\"YANDEX_DISK_URL\"),\n",
        "        }\n",
        "        final_url = download_info[\"base_url\"] + urlencode(\n",
        "            dict(public_key=download_info[\"public_key\"])\n",
        "        )\n",
        "        response = requests.get(final_url)\n",
        "        download_url = response.json()[\"href\"]\n",
        "        print(\"Downloading zip data...\")\n",
        "        download_response = requests.get(download_url)\n",
        "        print(\"Successfully downloaded\")\n",
        "        zip = zipfile.ZipFile(io.BytesIO(download_response.content))\n",
        "        zip.extractall(data_dir)\n",
        "    except requests.exceptions.ConnectTimeout as e:\n",
        "        print(f\"Connection timed out: {e}\")\n",
        "    except requests.exceptions.ReadTimeout as e:\n",
        "        print(f\"Read timed out: {e}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "XcekxHK8u7Dq"
      },
      "id": "XcekxHK8u7Dq",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DPRNN"
      ],
      "metadata": {
        "id": "hj3iZ7W99Arf"
      },
      "id": "hj3iZ7W99Arf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on val/test folders"
      ],
      "metadata": {
        "id": "2fWuSqCK9GzX"
      },
      "id": "2fWuSqCK9GzX"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "330d3388",
      "metadata": {
        "id": "330d3388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b14b0fc-31a3-4e64-d488-3fafc381fc84",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: cuda:0 with 14.64 GB free\n",
            "Creating dataset:   0% 0/500 [00:00<?, ?it/s]Downloading...\n",
            "From (original): https://drive.google.com/uc?id=179NgMsHo9TeZCLLtNWFVgRehDvzteMZE\n",
            "From (redirected): https://drive.google.com/uc?id=179NgMsHo9TeZCLLtNWFVgRehDvzteMZE&confirm=t&uuid=c66003d6-0dfd-401d-b2fd-aaf08b9fe045\n",
            "To: /content/AVSS/src/utils/lipreading/loaded_models/resnet18_dctcn.pth\n",
            "\n",
            "  0% 0.00/211M [00:00<?, ?B/s]\u001b[A\n",
            "  9% 19.4M/211M [00:00<00:01, 191MB/s]\u001b[A\n",
            " 23% 49.3M/211M [00:00<00:00, 252MB/s]\u001b[A\n",
            " 39% 81.3M/211M [00:00<00:00, 281MB/s]\u001b[A\n",
            " 52% 110M/211M [00:00<00:00, 281MB/s] \u001b[A\n",
            " 68% 143M/211M [00:00<00:00, 298MB/s]\u001b[A\n",
            "100% 211M/211M [00:00<00:00, 304MB/s]\n",
            "Lipreading model has been successfully loaded\n",
            "Creating dataset: 100% 500/500 [00:22<00:00, 22.18it/s]\n",
            "Creating dataset:   0% 0/3000 [00:00<?, ?it/s]Downloading...\n",
            "From (original): https://drive.google.com/uc?id=179NgMsHo9TeZCLLtNWFVgRehDvzteMZE\n",
            "From (redirected): https://drive.google.com/uc?id=179NgMsHo9TeZCLLtNWFVgRehDvzteMZE&confirm=t&uuid=4b085a09-c7fe-4fe0-98df-ca3c1571c794\n",
            "To: /content/AVSS/src/utils/lipreading/loaded_models/resnet18_dctcn.pth\n",
            "\n",
            "  0% 0.00/211M [00:00<?, ?B/s]\u001b[A\n",
            " 10% 21.0M/211M [00:00<00:00, 208MB/s]\u001b[A\n",
            " 25% 53.0M/211M [00:00<00:00, 273MB/s]\u001b[A\n",
            " 39% 81.8M/211M [00:00<00:00, 279MB/s]\u001b[A\n",
            " 52% 110M/211M [00:00<00:00, 239MB/s] \u001b[A\n",
            " 67% 141M/211M [00:00<00:00, 262MB/s]\u001b[A\n",
            " 83% 176M/211M [00:00<00:00, 288MB/s]\u001b[A\n",
            "100% 211M/211M [00:00<00:00, 276MB/s]\n",
            "Lipreading model has been successfully loaded\n",
            "Creating dataset: 100% 3000/3000 [00:30<00:00, 98.38it/s] \n",
            "DPRNN_TasNet(\n",
            "  (encoder): Encoder(\n",
            "    (dconv1d_block): Sequential(\n",
            "      (0): Conv1d(1, 64, kernel_size=(1,), stride=(1,))\n",
            "      (1): PReLU(num_parameters=1)\n",
            "      (2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
            "      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
            "      (4): PReLU(num_parameters=1)\n",
            "      (5): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
            "    )\n",
            "    (res_conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
            "    (out_conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (sep_start): Sequential(\n",
            "    (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
            "    (1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (separation): DPRNN(\n",
            "    (segmentation): Segmentation()\n",
            "    (dprnn_blocks): ModuleList(\n",
            "      (0-5): 6 x DPRNNBlock(\n",
            "        (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
            "        (intra_fc): Linear(in_features=256, out_features=64, bias=True)\n",
            "        (intra_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
            "        (inter_fc): Linear(in_features=256, out_features=64, bias=True)\n",
            "        (inter_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (overlap_add): OverlapAdd()\n",
            "  )\n",
            "  (sep_final): Sequential(\n",
            "    (0): PReLU(num_parameters=1)\n",
            "    (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
            "    (2): Sigmoid()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (dconv1d_block): Sequential(\n",
            "      (0): ConvTranspose1d(64, 64, kernel_size=(1,), stride=(1,))\n",
            "      (1): PReLU(num_parameters=1)\n",
            "      (2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
            "      (3): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (4): PReLU(num_parameters=1)\n",
            "      (5): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
            "    )\n",
            "    (out_conv): ConvTranspose1d(64, 1, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            ")\n",
            "Loading model weights from: data/models/dprnn.pth ...\n",
            "val: 100% 72/72 [07:00<00:00,  5.84s/it]\n",
            "test: 100% 429/429 [11:22<00:00,  1.59s/it]\n",
            "    val_SiSnri     : 2.6086437702178955\n",
            "    val_SiSdri     : -10.757514953613281\n",
            "    val_Pesq       : 1.2150799036026\n",
            "    val_Stoi       : 0.6942752003669739\n",
            "    test_SiSnri    : 0\n",
            "    test_SiSdri    : 0\n",
            "    test_Pesq      : 0\n",
            "    test_Stoi      : 0\n"
          ]
        }
      ],
      "source": [
        "!uv run inference.py inferencer.save_path=\"pred_dprnn_small_av\" \\\n",
        " batch_size=7 use_pit=True inferencer.from_pretrained={DPRNN_MODEL_PATH} download_name={download_name} model=dprnn -cn=inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on one folder with gt"
      ],
      "metadata": {
        "id": "vQ9Yvawo-FCc"
      },
      "id": "vQ9Yvawo-FCc"
    },
    {
      "cell_type": "code",
      "source": [
        "# !uv run inference.py inferencer.save_path=\"pred_dprnn_custom\" \\\n",
        "#  batch_size=7 datasets.test=null datasets.val.part=\"\" use_pit=True inferencer.from_pretrained={DPRNN_MODEL_PATH} download_name={download_name} model=dprnn -cn=inference"
      ],
      "metadata": {
        "id": "_kdQmKG45qNt"
      },
      "id": "_kdQmKG45qNt",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on one folder w/o gt"
      ],
      "metadata": {
        "id": "U_HiJrZID-L3"
      },
      "id": "U_HiJrZID-L3"
    },
    {
      "cell_type": "code",
      "source": [
        "# !uv run inference.py batch_size=7 inferencer.save_path=\"pred_dprnn_custom_test\" \\\n",
        "#  datasets.val=null datasets.test.part=\"\" use_pit=True inferencer.from_pretrained={DPRNN_MODEL_PATH} download_name={download_name} model=dprnn -cn=inference"
      ],
      "metadata": {
        "id": "5-MghQ43ECG7"
      },
      "id": "5-MghQ43ECG7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RTFS"
      ],
      "metadata": {
        "id": "zk5I-lzz9Eny"
      },
      "id": "zk5I-lzz9Eny"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on val/test folders"
      ],
      "metadata": {
        "id": "2oi_Of64-p7l"
      },
      "id": "2oi_Of64-p7l"
    },
    {
      "cell_type": "code",
      "source": [
        "!uv run inference.py inferencer.save_path=\"pred_rtfs_small_av\" \\\n",
        " inferencer.from_pretrained={RTFS_MODEL_PATH} download_name={download_name} model=rtfs-4-reuse -cn=inference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQfgIAtvz2g5",
        "outputId": "cdbb5092-fa20-4294-8c2e-00432f802ac3"
      },
      "id": "lQfgIAtvz2g5",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: cuda:0 with 14.64 GB free\n",
            "Creating dataset: 100% 500/500 [00:07<00:00, 62.67it/s]\n",
            "Creating dataset: 100% 3000/3000 [00:17<00:00, 170.15it/s]\n",
            "RTFSModel(\n",
            "  (stft): TransformSTFT()\n",
            "  (audio_encoder): RTFSAudioEncoder(\n",
            "    (conv): Conv2d(2, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (ap_block): RTFSBlock(\n",
            "    (compressor): CompressorBlock(\n",
            "      (dimension_compression_layer): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (tf_compression_layers): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "        (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "      )\n",
            "    )\n",
            "    (reconstructor): ReconstructionBlock(\n",
            "      (g_fuse_layers): ModuleList(\n",
            "        (0-2): 3 x TFARUnit(\n",
            "          (w1_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            (2): Sigmoid()\n",
            "          )\n",
            "          (w2_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "          (w3_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (residual_fuse_layers): ModuleList(\n",
            "        (0-1): 2 x TFARUnit(\n",
            "          (w1_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            (2): Sigmoid()\n",
            "          )\n",
            "          (w2_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "          (w3_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dimension_upsampling_layer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (unfold): Unfold(kernel_size=(8, 1), dilation=1, padding=0, stride=1)\n",
            "    (freq_sru): LSTM(1024, 128, num_layers=4, bidirectional=True)\n",
            "    (time_sru): LSTM(1024, 128, num_layers=4, bidirectional=True)\n",
            "    (freq_tconv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(1,))\n",
            "    (time_tconv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(1,))\n",
            "    (attn): TFSelfAttention(\n",
            "      (q_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (k_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (v_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): PReLU(num_parameters=1)\n",
            "      (norm): ChannelFrequencyLayerNorm((128, 64), eps=1e-08, elementwise_affine=True)\n",
            "      (out_pathway): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): PReLU(num_parameters=1)\n",
            "        (2): ChannelFrequencyLayerNorm((128, 64), eps=1e-08, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (vp_block): VPEncoder(\n",
            "    (compressor): CompressorBlock(\n",
            "      (dimension_compression_layer): Conv1d(50, 128, kernel_size=(1,), stride=(1,))\n",
            "      (tf_compression_layers): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,), groups=128)\n",
            "        (1): Conv1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,), groups=128)\n",
            "      )\n",
            "    )\n",
            "    (reconstructor): ReconstructionBlock(\n",
            "      (g_fuse_layers): ModuleList(\n",
            "        (0-2): 3 x TFARUnit(\n",
            "          (w1_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            (2): Sigmoid()\n",
            "          )\n",
            "          (w2_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "          (w3_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (residual_fuse_layers): ModuleList(\n",
            "        (0-1): 2 x TFARUnit(\n",
            "          (w1_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            (2): Sigmoid()\n",
            "          )\n",
            "          (w2_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "          (w3_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dimension_upsampling_layer): Conv1d(128, 50, kernel_size=(1,), stride=(1,))\n",
            "    )\n",
            "    (attn): TDANetSelfAttention(\n",
            "      (mhsa): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (ffn): FFN(\n",
            "        (ffn): Sequential(\n",
            "          (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (1): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), groups=256)\n",
            "          (5): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "          (6): PReLU(num_parameters=1)\n",
            "          (7): Dropout(p=0.1, inplace=False)\n",
            "          (8): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (9): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          (10): PReLU(num_parameters=1)\n",
            "          (11): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (caf_block): RTFSCAFBlock(\n",
            "    (visual_attention_pathway): Sequential(\n",
            "      (0): Conv1d(50, 1024, kernel_size=(1,), stride=(1,))\n",
            "      (1): GlobalLayerNorm(1, 1024, eps=1e-08, affine=True)\n",
            "      (2): AvgPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0)\n",
            "      (3): Softmax(dim=-1)\n",
            "    )\n",
            "    (audio_attention_pathway): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "    )\n",
            "    (visual_gated_pathway): Sequential(\n",
            "      (0): Conv1d(50, 256, kernel_size=(1,), stride=(1,))\n",
            "      (1): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "    )\n",
            "    (audio_gated_pathway): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (rtfs_blocks): ModuleList(\n",
            "    (0-2): 3 x RTFSBlock(\n",
            "      (compressor): CompressorBlock(\n",
            "        (dimension_compression_layer): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (tf_compression_layers): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "          (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "        )\n",
            "      )\n",
            "      (reconstructor): ReconstructionBlock(\n",
            "        (g_fuse_layers): ModuleList(\n",
            "          (0-2): 3 x TFARUnit(\n",
            "            (w1_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "              (2): Sigmoid()\n",
            "            )\n",
            "            (w2_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            )\n",
            "            (w3_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (residual_fuse_layers): ModuleList(\n",
            "          (0-1): 2 x TFARUnit(\n",
            "            (w1_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "              (2): Sigmoid()\n",
            "            )\n",
            "            (w2_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            )\n",
            "            (w3_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (dimension_upsampling_layer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (unfold): Unfold(kernel_size=(8, 1), dilation=1, padding=0, stride=1)\n",
            "      (freq_sru): LSTM(1024, 128, num_layers=4, bidirectional=True)\n",
            "      (time_sru): LSTM(1024, 128, num_layers=4, bidirectional=True)\n",
            "      (freq_tconv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(1,))\n",
            "      (time_tconv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(1,))\n",
            "      (attn): TFSelfAttention(\n",
            "        (q_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (k_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (v_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): PReLU(num_parameters=1)\n",
            "        (norm): ChannelFrequencyLayerNorm((128, 64), eps=1e-08, elementwise_affine=True)\n",
            "        (out_pathway): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): PReLU(num_parameters=1)\n",
            "          (2): ChannelFrequencyLayerNorm((128, 64), eps=1e-08, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (separator): RTFSSeparator(\n",
            "    (mask_pathway): Sequential(\n",
            "      (0): PReLU(num_parameters=1)\n",
            "      (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (audio_decoder): RTFSDecoder(\n",
            "    (deconv2d): ConvTranspose2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "All parameters: 5897786\n",
            "Trainable parameters: 5897786\n",
            "Loading model weights from: data/models/rtfs-4-reuse.pth ...\n",
            "val: 100% 63/63 [04:41<00:00,  4.47s/it]\n",
            "test: 100% 375/375 [13:59<00:00,  2.24s/it]\n",
            "    val_SiSnri     : 8.434468269348145\n",
            "    val_SiSdri     : 8.43233585357666\n",
            "    val_Pesq       : 1.9817436933517456\n",
            "    val_Stoi       : 0.8320121765136719\n",
            "    test_SiSnri    : 0\n",
            "    test_SiSdri    : 0\n",
            "    test_Pesq      : 0\n",
            "    test_Stoi      : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on one folder with gt"
      ],
      "metadata": {
        "id": "RKveifCiFWOE"
      },
      "id": "RKveifCiFWOE"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "548f8e73",
      "metadata": {
        "id": "548f8e73"
      },
      "outputs": [],
      "source": [
        "# !uv run inference.py inferencer.save_path=\"pred_rtfs_custom\" \\\n",
        "#  inferencer.from_pretrained={RTFS_MODEL_PATH} datasets.test=null datasets.val.part=\"\" download_name={download_name} model=rtfs-4-reuse -cn=inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on one folder w/o gt"
      ],
      "metadata": {
        "id": "ybLYFQJEFZWT"
      },
      "id": "ybLYFQJEFZWT"
    },
    {
      "cell_type": "code",
      "source": [
        "# !uv run inference.py inferencer.save_path=\"pred_rtfs_custom_test\" \\\n",
        "#  inferencer.from_pretrained={RTFS_MODEL_PATH} datasets.val=null datasets.test.part=\"\" download_name={download_name} model=rtfs-4-reuse -cn=inference"
      ],
      "metadata": {
        "id": "T8ngMatFFbk-"
      },
      "id": "T8ngMatFFbk-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calc metrics"
      ],
      "metadata": {
        "id": "GgKmWKE9-03O"
      },
      "id": "GgKmWKE9-03O"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "efc16ed5",
      "metadata": {
        "id": "efc16ed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a3c3be-f963-4f10-f4b4-624896b6fdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Metrics...: 100% 500/500 [02:04<00:00,  4.01it/s]\n",
            "Average Metrics:\n",
            "STOI: 0.8330\n",
            "PESQ: 1.9828\n",
            "SI-SDR-I: 8.4503\n",
            "SI-SNR-I: 8.4524\n"
          ]
        }
      ],
      "source": [
        "#calculate metrics on predictions on the dla_dataset_small_av folder (download_name) of rtfs model\n",
        "# download_name =\n",
        "\n",
        "# name of the folder, where you stored models predictions\n",
        "preds_folder_name = \"pred_rtfs_small_av\"\n",
        "\n",
        "# should be empty if the dataset was one folder like, e.g. w/o partitions\n",
        "# should be \"val\" or other partition name, if there were partitions in provided dataset,\n",
        "# also provided pratition should contain gt\n",
        "part = \"val\"\n",
        "\n",
        "# should be equal to part if the dataset had partitions,\n",
        "# if the dataset was one folder like: set \"val\" if you ran with gt, \"test\" if you ran w/o gt\n",
        "preds_part = part\n",
        "\n",
        "!uv run calc_metrics.py --gt_s1=data/datasets/{download_name}/audio/{part}/s1 --gt_s2=data/datasets/{download_name}/audio/{part}/s2 \\\n",
        "    --pred_s1=data/saved/{preds_folder_name}/{preds_part}/s1 --pred_s2=data/saved/{preds_folder_name}/{preds_part}/s2  --mix=data/datasets/{download_name}/audio/{part}/mix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus, RTFS Model (num params + secs per batch of size 1)"
      ],
      "metadata": {
        "id": "sktOAfW1-7kF"
      },
      "id": "sktOAfW1-7kF"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0c8ffcd0",
      "metadata": {
        "id": "0c8ffcd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e22fe46-49b1-485e-b687-5de31901c710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dataset: 100% 500/500 [00:09<00:00, 54.63it/s]\n",
            "RTFSModel(\n",
            "  (stft): TransformSTFT()\n",
            "  (audio_encoder): RTFSAudioEncoder(\n",
            "    (conv): Conv2d(2, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (ap_block): RTFSBlock(\n",
            "    (compressor): CompressorBlock(\n",
            "      (dimension_compression_layer): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (tf_compression_layers): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "        (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "      )\n",
            "    )\n",
            "    (reconstructor): ReconstructionBlock(\n",
            "      (g_fuse_layers): ModuleList(\n",
            "        (0-2): 3 x TFARUnit(\n",
            "          (w1_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            (2): Sigmoid()\n",
            "          )\n",
            "          (w2_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "          (w3_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (residual_fuse_layers): ModuleList(\n",
            "        (0-1): 2 x TFARUnit(\n",
            "          (w1_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            (2): Sigmoid()\n",
            "          )\n",
            "          (w2_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "          (w3_pathway): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dimension_upsampling_layer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (unfold): Unfold(kernel_size=(8, 1), dilation=1, padding=0, stride=1)\n",
            "    (freq_sru): LSTM(1024, 128, num_layers=4, bidirectional=True)\n",
            "    (time_sru): LSTM(1024, 128, num_layers=4, bidirectional=True)\n",
            "    (freq_tconv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(1,))\n",
            "    (time_tconv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(1,))\n",
            "    (attn): TFSelfAttention(\n",
            "      (q_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (k_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (v_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): PReLU(num_parameters=1)\n",
            "      (norm): ChannelFrequencyLayerNorm((128, 64), eps=1e-08, elementwise_affine=True)\n",
            "      (out_pathway): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): PReLU(num_parameters=1)\n",
            "        (2): ChannelFrequencyLayerNorm((128, 64), eps=1e-08, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (vp_block): VPEncoder(\n",
            "    (compressor): CompressorBlock(\n",
            "      (dimension_compression_layer): Conv1d(50, 128, kernel_size=(1,), stride=(1,))\n",
            "      (tf_compression_layers): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,), groups=128)\n",
            "        (1): Conv1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,), groups=128)\n",
            "      )\n",
            "    )\n",
            "    (reconstructor): ReconstructionBlock(\n",
            "      (g_fuse_layers): ModuleList(\n",
            "        (0-2): 3 x TFARUnit(\n",
            "          (w1_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            (2): Sigmoid()\n",
            "          )\n",
            "          (w2_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "          (w3_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (residual_fuse_layers): ModuleList(\n",
            "        (0-1): 2 x TFARUnit(\n",
            "          (w1_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            (2): Sigmoid()\n",
            "          )\n",
            "          (w2_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same, groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "          (w3_pathway): Sequential(\n",
            "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
            "            (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dimension_upsampling_layer): Conv1d(128, 50, kernel_size=(1,), stride=(1,))\n",
            "    )\n",
            "    (attn): TDANetSelfAttention(\n",
            "      (mhsa): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (ffn): FFN(\n",
            "        (ffn): Sequential(\n",
            "          (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (1): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), groups=256)\n",
            "          (5): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "          (6): PReLU(num_parameters=1)\n",
            "          (7): Dropout(p=0.1, inplace=False)\n",
            "          (8): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "          (9): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "          (10): PReLU(num_parameters=1)\n",
            "          (11): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (caf_block): RTFSCAFBlock(\n",
            "    (visual_attention_pathway): Sequential(\n",
            "      (0): Conv1d(50, 1024, kernel_size=(1,), stride=(1,))\n",
            "      (1): GlobalLayerNorm(1, 1024, eps=1e-08, affine=True)\n",
            "      (2): AvgPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0)\n",
            "      (3): Softmax(dim=-1)\n",
            "    )\n",
            "    (audio_attention_pathway): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "    )\n",
            "    (visual_gated_pathway): Sequential(\n",
            "      (0): Conv1d(50, 256, kernel_size=(1,), stride=(1,))\n",
            "      (1): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "    )\n",
            "    (audio_gated_pathway): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): GlobalLayerNorm(1, 256, eps=1e-08, affine=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (rtfs_blocks): ModuleList(\n",
            "    (0-2): 3 x RTFSBlock(\n",
            "      (compressor): CompressorBlock(\n",
            "        (dimension_compression_layer): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (tf_compression_layers): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "          (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "        )\n",
            "      )\n",
            "      (reconstructor): ReconstructionBlock(\n",
            "        (g_fuse_layers): ModuleList(\n",
            "          (0-2): 3 x TFARUnit(\n",
            "            (w1_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "              (2): Sigmoid()\n",
            "            )\n",
            "            (w2_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            )\n",
            "            (w3_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (residual_fuse_layers): ModuleList(\n",
            "          (0-1): 2 x TFARUnit(\n",
            "            (w1_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "              (2): Sigmoid()\n",
            "            )\n",
            "            (w2_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), padding=same, groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            )\n",
            "            (w3_pathway): Sequential(\n",
            "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "              (1): GlobalLayerNorm(1, 128, eps=1e-08, affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (dimension_upsampling_layer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (unfold): Unfold(kernel_size=(8, 1), dilation=1, padding=0, stride=1)\n",
            "      (freq_sru): LSTM(1024, 128, num_layers=4, bidirectional=True)\n",
            "      (time_sru): LSTM(1024, 128, num_layers=4, bidirectional=True)\n",
            "      (freq_tconv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(1,))\n",
            "      (time_tconv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(1,))\n",
            "      (attn): TFSelfAttention(\n",
            "        (q_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (k_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (v_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): PReLU(num_parameters=1)\n",
            "        (norm): ChannelFrequencyLayerNorm((128, 64), eps=1e-08, elementwise_affine=True)\n",
            "        (out_pathway): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): PReLU(num_parameters=1)\n",
            "          (2): ChannelFrequencyLayerNorm((128, 64), eps=1e-08, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (separator): RTFSSeparator(\n",
            "    (mask_pathway): Sequential(\n",
            "      (0): PReLU(num_parameters=1)\n",
            "      (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (audio_decoder): RTFSDecoder(\n",
            "    (deconv2d): ConvTranspose2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "All parameters: 5897786\n",
            "Trainable parameters: 5897786\n",
            "Loading model weights from: data/models/rtfs-4-reuse.pth ...\n",
            "val: 100% 1/1 [00:14<00:00, 14.04s/it]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "!uv run inference.py inferencer.save_path=\"\" \\\n",
        "    batch_size=1 metrics.inference=[]\\\n",
        "    inferencer.from_pretrained={RTFS_MODEL_PATH} \\\n",
        "    download_name=dla_dataset_small_av\\\n",
        "    model=rtfs-4-reuse inferencer.device=cpu  datasets.test=null \\\n",
        "    +datasets.val.limit=1 -cn=inference\n",
        "\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "71bd3cdc",
      "metadata": {
        "id": "71bd3cdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff59bd7-7a20-4585-ecab-2b44f0cc20a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total elapsed: 30.08139443397522 seconds\n",
            "Per batch Time:  9  seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"Total elapsed:\", end - start, \"seconds\")\n",
        "print(\"Per batch Time: \", 9, \" seconds\") #can be seen on the tqdm bar: val: 100% 1/1 [00:09<00:00,  9.09s/it]\n",
        "#you can increase batch_size and divide by batch_size to see time the implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KNz_bj3daGrS"
      },
      "id": "KNz_bj3daGrS",
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}